# Master thesis Explainable AI
Topic: To what extent does the form of presentation (textual, visual, hybrid) in combination with AI explanation types (input influence-based, sensitivity-based) influence end users' acceptance of AI-based decision support systems?

To address this question, I created a user-friendly React app that takes participants through a scenario where they play the role of insurance company employees. In this role, they must assess surrogate based explanations (based on LIME) of an AI system's recommendations for customers' data-driven price ratings.
